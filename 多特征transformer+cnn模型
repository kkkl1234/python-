import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_absolute_error
import random
from tqdm import tqdm
import os
import warnings
warnings.filterwarnings('ignore')

# 基础配置
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
os.makedirs("results", exist_ok=True)

# 评估指标计算
def calculate_mae(y_true, y_pred):
    return mean_absolute_error(y_true, y_pred)

def calculate_mape(y_true, y_pred, epsilon=1e-8):
    y_true = np.array(y_true) + epsilon
    y_pred = np.array(y_pred)
    return round(np.mean(np.abs((y_true - y_pred) / y_true)) * 100, 4)

# 数据集类
class MultiFeatureTimeSeriesDataset(Dataset):
    def __init__(self, feat_data, target_data, seq_len, pred_len=1):
        self.feat_data = feat_data
        self.target_data = target_data
        self.seq_len = seq_len
        self.pred_len = pred_len
        
        if len(feat_data) != len(target_data):
            raise ValueError(f"特征与目标长度不一致（{len(feat_data)} vs {len(target_data)}）")
        if len(feat_data) < seq_len + pred_len:
            raise ValueError(f"数据长度不足（需≥{seq_len+pred_len}，实际{len(feat_data)}）")
        self.length = len(feat_data) - seq_len - pred_len + 1

    def __len__(self):
        return self.length

    def __getitem__(self, idx):
        if idx < 0 or idx >= self.length:
            raise IndexError(f"索引{idx}超出范围（0-{self.length-1}）")
        x = self.feat_data[idx:idx+self.seq_len]
        y = self.target_data[idx+self.seq_len:idx+self.seq_len+self.pred_len]
        return torch.tensor(x, dtype=torch.float32), torch.tensor(y.reshape(-1, 1), dtype=torch.float32)

# 模型类
class CNNTransformerModel(nn.Module):
    def __init__(self, input_dim=5, hidden_dim=64, num_heads=4, num_transformer_layers=2, kernel_size=3, pred_len=1):
        super().__init__()
        self.pred_len = pred_len
        
        if hidden_dim % num_heads != 0:
            raise ValueError(f"hidden_dim({hidden_dim})必须能被num_heads({num_heads})整除")
        if kernel_size % 2 == 0:
            raise ValueError(f"kernel_size({kernel_size})应为奇数")
        
        self.cnn = nn.Sequential(
            nn.Conv1d(input_dim, hidden_dim, kernel_size, padding=kernel_size//2),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Conv1d(hidden_dim, hidden_dim, kernel_size, padding=kernel_size//2),
            nn.ReLU(),
            nn.Dropout(0.2)
        )
        
        self.transformer_encoder = nn.TransformerEncoder(
            nn.TransformerEncoderLayer(
                d_model=hidden_dim, nhead=num_heads, dim_feedforward=hidden_dim*4,
                batch_first=True, norm_first=True, dropout=0.1
            ),
            num_layers=num_transformer_layers
        )
        
        self.fc = nn.Linear(hidden_dim, pred_len)

    def forward(self, x):
        x_cnn = x.transpose(1, 2)
        x_cnn = self.cnn(x_cnn).transpose(1, 2)
        x_trans = self.transformer_encoder(x_cnn)
        return self.fc(x_trans[:, -1, :]).unsqueeze(-1)

# 数据加载
def load_public_data():
    data_path = "consumption.csv"
    df = pd.read_csv(data_path)
    
    df["DateTime"] = pd.to_datetime(df["DateTime"])  
    df.set_index("DateTime", inplace=True)  
    
    df_daily_mean = df.resample('D').mean() 
    return df_daily_mean

# 探索性数据分析
def exploratory_data_analysis(df):
    print("\n" + "="*50)
    print("探索性数据分析")
    print("="*50)
    
    print(f"数据形状：{df.shape} | 时间范围：{df.index.min()} 至 {df.index.max()}")
    print("\n描述统计：")
    print(df.describe().round(2))
    
    if df.isnull().sum().sum() > 0:
        print("\n缺失值填充（前向+后向）：")
        df = df.fillna(method='ffill').fillna(method='bfill')
        print(f"填充后缺失值：{df.isnull().sum().sum()}")
    
    # 目标变量时间序列图
    plt.figure(figsize=(15, 4))
    plt.plot(df.index, df['Zone 3  Power Consumption'], color='#2E86AB', linewidth=1.5)
    plt.title('Zone 3 电力消耗时间序列', fontsize=12, fontweight='bold')
    plt.xlabel('日期'), plt.ylabel('电力消耗 (kW)'), plt.grid(alpha=0.3)
    plt.tight_layout(), plt.savefig("results/target_time_series.png", dpi=300), plt.close()
    
    # 特征相关性热力图
    plt.figure(figsize=(8, 6))
    corr = df.corr()
    plt.imshow(corr, cmap='RdBu_r', vmin=-1, vmax=1)
    plt.colorbar(label='相关系数'), plt.xticks(range(len(corr)), corr.columns, rotation=45, ha='right')
    plt.yticks(range(len(corr)), corr.columns), plt.title('特征-目标相关性热力图', fontsize=12, fontweight='bold')
    for i in range(len(corr)):
        for j in range(len(corr)):
            plt.text(j, i, f'{corr.iloc[i, j]:.2f}', ha='center', va='center', fontsize=8)
    plt.tight_layout(), plt.savefig("results/correlation_heatmap.png", dpi=300), plt.close()
    
    print("EDA可视化已保存至 results/ 目录")
    return df

# 数据预处理
def preprocess_data(df):
    FEATURE_COLS = ['Temperature', 'Humidity', 'Wind Speed', 'general diffuse flows', 'diffuse flows']
    TARGET_COL = 'Zone 3  Power Consumption'
    
    feat_data = df[FEATURE_COLS].values
    target_series = df[TARGET_COL].values
    
    # 目标序列一阶差分平稳化
    diff_target = np.diff(target_series, n=1)
    feat_data_aligned = feat_data[1:]
    
    # 标准化处理
    feat_scaler = StandardScaler()
    feat_data_scaled = feat_scaler.fit_transform(feat_data_aligned)
    
    target_scaler = StandardScaler()
    diff_target_scaled = target_scaler.fit_transform(diff_target.reshape(-1, 1)).flatten()
    
    # 划分训练/测试集
    train_size = int(0.8 * len(feat_data_scaled))
    train_feat, test_feat = feat_data_scaled[:train_size], feat_data_scaled[train_size:]
    train_target, test_target = diff_target_scaled[:train_size], diff_target_scaled[train_size:]
    
    print(f"数据预处理完成：训练集{len(train_feat)}条 | 测试集{len(test_feat)}条")
    return {
        'train_feat': train_feat, 'test_feat': test_feat,
        'train_target': train_target, 'test_target': test_target,
        'feat_scaler': feat_scaler, 'target_scaler': target_scaler,
        'original_target': target_series
    }

# 预测函数
def predict(model, loader):
    model.eval()
    preds, trues = [], []
    with torch.no_grad():
        for x, y in loader:
            x, y = x.to(DEVICE), y.to(DEVICE)
            pred = model(x)
            preds.extend(pred.cpu().numpy().flatten())
            trues.extend(y.cpu().numpy().flatten())
    return np.array(preds), np.array(trues)

# 逆变换函数
def inverse_transform(pred_scaled, target_scaler, original_target, seq_len, train_size, is_train=True):
    pred_diff = target_scaler.inverse_transform(pred_scaled.reshape(-1, 1)).flatten()
    start_idx = seq_len + 1
    if not is_train:
        start_idx += train_size
    prev_vals = original_target[start_idx-1 : start_idx-1 + len(pred_diff)]
    return prev_vals + pred_diff

# 训练与调参
def train_eval(prep_data, pred_len=1):
    print("\n" + "="*50)
    print("CNN-Transformer 训练与调参")
    print("="*50)
    
    # 超参数搜索空间
    param_grid = {
        'SEQ_LEN': [14, 28],
        'hidden_dim': [32, 64, 128],
        'num_heads': [2, 4, 8],
        'num_transformer_layers': [1, 2, 3],
        'kernel_size': [3, 5],
        'BATCH_SIZE': [16, 32],
        'LEARNING_RATE': [1e-4, 5e-4],
        'epochs': [40]
    }
    
    # 生成有效参数组合
    n_trials = 20
    valid_params = []
    while len(valid_params) < n_trials:
        params = {k: random.choice(v) for k, v in param_grid.items()}
        if params['hidden_dim'] % params['num_heads'] == 0:
            valid_params.append(params)
    
    # 搜索最优参数
    best_mae = float('inf')
    best_params = None
    best_model = None
    
    for i, params in enumerate(tqdm(valid_params, desc="调参进度")):
        try:
            # 构建数据集
            train_dataset = MultiFeatureTimeSeriesDataset(
                prep_data['train_feat'], prep_data['train_target'],
                seq_len=params['SEQ_LEN'], pred_len=pred_len
            )
            test_dataset = MultiFeatureTimeSeriesDataset(
                prep_data['test_feat'], prep_data['test_target'],
                seq_len=params['SEQ_LEN'], pred_len=pred_len
            )
            
            if len(train_dataset) < 10 or len(test_dataset) < 5:
                continue
            
            # 数据加载器
            train_loader = DataLoader(train_dataset, batch_size=params['BATCH_SIZE'], shuffle=False)
            test_loader = DataLoader(test_dataset, batch_size=params['BATCH_SIZE'], shuffle=False)
            
            # 初始化模型
            model = CNNTransformerModel(
                input_dim=5,
                hidden_dim=params['hidden_dim'],
                num_heads=params['num_heads'],
                num_transformer_layers=params['num_transformer_layers'],
                kernel_size=params['kernel_size'],
                pred_len=pred_len
            ).to(DEVICE)
            
            # 训练配置
            criterion = nn.L1Loss()
            optimizer = optim.Adam(model.parameters(), lr=params['LEARNING_RATE'], weight_decay=1e-5)
            epochs = params['epochs']
            
            # 模型训练
            model.train()
            for _ in range(epochs):
                for x_batch, y_batch in train_loader:
                    x_batch, y_batch = x_batch.to(DEVICE), y_batch.to(DEVICE)
                    y_pred = model(x_batch)
                    loss = criterion(y_pred, y_batch)
                    
                    optimizer.zero_grad()
                    loss.backward()
                    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
                    optimizer.step()
            
            # 测试集预测与评估
            test_pred_scaled, test_true_scaled = predict(model, test_loader)
            test_pred = inverse_transform(
                test_pred_scaled, prep_data['target_scaler'], prep_data['original_target'],
                params['SEQ_LEN'], len(prep_data['train_feat']), is_train=False
            )
            test_true = inverse_transform(
                test_true_scaled, prep_data['target_scaler'], prep_data['original_target'],
                params['SEQ_LEN'], len(prep_data['train_feat']), is_train=False
            )
            
            mae, mape = calculate_mae(test_true, test_pred), calculate_mape(test_true, test_pred)
            
            # 更新最优模型
            if mae < best_mae:
                best_mae = mae
                best_mape = mape
                best_params = params
                best_model = model
        
        except Exception as e:
            print(f"第{i+1}组参数训练失败：{str(e)}")
            continue
    
    # 保存最优模型
    torch.save({
        'model_state_dict': best_model.state_dict(),
        'params': best_params,
        'feat_scaler': prep_data['feat_scaler'],
        'target_scaler': prep_data['target_scaler'],
        'test_mae': best_mae,
        'test_mape': best_mape
    }, "results/best_model.pth")
    
    # 最优模型可视化
    train_dataset = MultiFeatureTimeSeriesDataset(
        prep_data['train_feat'], prep_data['train_target'],
        seq_len=best_params['SEQ_LEN'], pred_len=pred_len
    )
    train_loader = DataLoader(train_dataset, batch_size=best_params['BATCH_SIZE'], shuffle=False)
    test_loader = DataLoader(
        MultiFeatureTimeSeriesDataset(prep_data['test_feat'], prep_data['test_target'],
                                     seq_len=best_params['SEQ_LEN'], pred_len=pred_len),
        batch_size=best_params['BATCH_SIZE'], shuffle=False
    )
    
    # 训练集预测
    train_pred_scaled, train_true_scaled = predict(best_model, train_loader)
    train_pred = inverse_transform(
        train_pred_scaled, prep_data['target_scaler'], prep_data['original_target'],
        best_params['SEQ_LEN'], len(prep_data['train_feat']), is_train=True
    )
    train_true = inverse_transform(
        train_true_scaled, prep_data['target_scaler'], prep_data['original_target'],
        best_params['SEQ_LEN'], len(prep_data['train_feat']), is_train=True
    )
    
    # 计算训练集指标
    train_mae, train_mape = calculate_mae(train_true, train_pred), calculate_mape(train_true, train_pred)
    
    # 绘制可视化图
    fig, ax = plt.subplots(figsize=(15, 6))
    train_steps = range(len(train_true))
    test_steps = range(len(train_true), len(train_true) + len(test_true))
    
    ax.plot(train_steps, train_true, color='#2E86AB', linewidth=2.0, 
            label=f'训练集真实值 (MAE={train_mae:.2f} kW)', alpha=0.8)
    ax.plot(train_steps, train_pred, color='#F2A154', linewidth=1.8, label='训练集预测值', alpha=0.9)
    ax.plot(test_steps, test_true, color='#2E86AB', linewidth=2.5, 
            label=f'测试集真实值 (MAE={best_mae:.2f} kW)', alpha=0.8)
    ax.plot(test_steps, test_pred, color='#E63946', linewidth=2.2, label='测试集预测值', linestyle='--', alpha=0.9)
    ax.axvline(x=len(train_true)-1, color='black', linestyle=':', linewidth=2.0, label='训练/测试分割线')
    
    ax.set_title('Zone 3 电力消耗预测结果（5特征+CNN-Transformer）', fontsize=14, fontweight='bold')
    ax.set_xlabel('时间步'), ax.set_ylabel('电力消耗 (kW)'), ax.grid(alpha=0.3), ax.legend()
    plt.tight_layout(), plt.savefig("results/prediction_result.png", dpi=300), plt.close()
    
    # 输出最优结果
    print(f"\n最优结果：")
    print(f"最优参数：{best_params}")
    print(f"训练集MAE：{train_mae:.6f} | MAPE：{train_mape:.4f}%")
    print(f"测试集MAE：{best_mae:.6f} | MAPE：{best_mape:.4f}%")
    print("模型与可视化已保存至 results/ 目录")
    
    return {
        "params": best_params,
        "train_mae": train_mae,
        "test_mae": best_mae,
        "test_mape": best_mape
    }

# 主函数
def main():
    print("="*60)
    print("多特征电力消耗预测（Zone 3）")
    print("="*60)
    
    try:
        # 数据加载
        df = load_public_data()
        # 探索性数据分析
        df = exploratory_data_analysis(df)
        # 数据预处理
        prep_data = preprocess_data(df)
        # 模型训练与调参
        result = train_eval(prep_data, pred_len=1)
        
        print("\n" + "="*60)
        print("项目运行完成！")
        print("="*60)
        print("输出文件清单：")
        print("- EDA可视化：results/ 目录（时间序列图+相关性热力图）")
        print("- 最优模型权重：results/best_model.pth")
        print("- 预测结果图：results/prediction_result.png")
    
    except Exception as e:
        print(f"\n运行失败：{str(e)}")
        raise

if __name__ == "__main__":
    main()
