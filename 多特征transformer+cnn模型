import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_absolute_error
import random
from tqdm import tqdm
import os
import warnings
warnings.filterwarnings('ignore')

# 基础配置
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
os.makedirs("best_model", exist_ok=True)
os.makedirs("eda_plots", exist_ok=True)

# 数据加载
def load_data(data_path=None):
    try:
        if data_path and os.path.exists(data_path):
            df = pd.read_csv(data_path, sep=';', low_memory=False)
        else:
            url = "https://archive.ics.uci.edu/ml/machine-learning-databases/00235/household_power_consumption.zip"
            df = pd.read_csv(url, sep=';', compression='zip', low_memory=False)
        print("数据加载成功")
        return df
    except FileNotFoundError:
        raise FileNotFoundError("数据文件未找到，请检查路径或网络")
    except Exception as e:
        raise RuntimeError(f"数据加载失败：{str(e)}")

# 探索性数据分析
def exploratory_data_analysis(df):
    print("\n" + "="*50)
    print("探索性数据分析")
    print("="*50)
    
    print(f"数据形状：{df.shape} | 列名：{list(df.columns)}")
    missing_stats = df.isnull().sum()
    missing_ratio = (missing_stats / len(df) * 100).round(2)
    missing_df = pd.DataFrame({"缺失数量": missing_stats, "缺失比例(%)": missing_ratio})
    print("\n缺失值统计：")
    print(missing_df[missing_df["缺失数量"] > 0])
    
    # 数据清洗
    df['datetime'] = pd.to_datetime(df['Date'] + ' ' + df['Time'], format='%d/%m/%Y %H:%M:%S', errors='coerce')
    numeric_cols = ['Global_active_power', 'Global_reactive_power', 'Voltage', 
                   'Global_intensity', 'Sub_metering_1', 'Sub_metering_2', 'Sub_metering_3']
    for col in numeric_cols:
        df[col] = pd.to_numeric(df[col], errors='coerce')
    
    df_daily = df.resample('D', on='datetime').mean().reset_index()
    df_daily = df_daily.fillna(method='ffill').fillna(method='bfill')
    print(f"\n清洗后形状：{df_daily.shape} | 缺失值：{df_daily.isnull().sum().sum()}")
    
    # 时间序列可视化
    plt.figure(figsize=(15, 5))
    plt.plot(df_daily['datetime'], df_daily['Global_active_power'], color='#2E86AB', linewidth=1.5)
    plt.title('日均电力消耗时间序列', fontsize=14, fontweight='bold')
    plt.xlabel('日期'), plt.ylabel('全局有功功率 (kW)'), plt.grid(alpha=0.3)
    plt.tight_layout(), plt.savefig("eda_plots/power_time_series.png", dpi=300), plt.close()
    
    # 相关性热力图
    corr_matrix = df_daily[numeric_cols].corr()
    plt.figure(figsize=(10, 8))
    plt.imshow(corr_matrix, cmap='RdBu_r', vmin=-1, vmax=1)
    plt.colorbar(label='相关系数'), plt.title('特征相关性热力图', fontsize=14, fontweight='bold')
    plt.xticks(range(len(numeric_cols)), numeric_cols, rotation=45, ha='right')
    plt.yticks(range(len(numeric_cols)), numeric_cols)
    for i in range(len(numeric_cols)):
        for j in range(len(numeric_cols)):
            plt.text(j, i, f'{corr_matrix.iloc[i, j]:.2f}', ha='center', va='center', fontsize=9)
    plt.tight_layout(), plt.savefig("eda_plots/correlation_heatmap.png", dpi=300), plt.close()
    
    print("EDA可视化已保存至 eda_plots/ 目录")
    return df_daily

# 数据集类
class MultiFeatureTimeSeriesDataset(Dataset):
    def __init__(self, feat_data, target_data, seq_len, pred_len=1):
        self.feat_data = feat_data
        self.target_data = target_data
        self.seq_len = seq_len
        self.pred_len = pred_len
        
        if len(feat_data) != len(target_data):
            raise ValueError(f"特征与目标数据长度不一致（{len(feat_data)} vs {len(target_data)}）")
        if seq_len + pred_len > len(feat_data):
            raise ValueError("序列长度+预测长度超过数据总长度")
        
        self.length = len(feat_data) - seq_len - pred_len + 1

    def __len__(self):
        return self.length

    def __getitem__(self, idx):
        if idx < 0 or idx >= self.length:
            raise IndexError(f"索引 {idx} 超出范围")
        
        x = self.feat_data[idx:idx+self.seq_len]
        y = self.target_data[idx+self.seq_len:idx+self.seq_len+self.pred_len]
        return torch.tensor(x, dtype=torch.float32), torch.tensor(y.reshape(-1, 1), dtype=torch.float32)

# 模型类
class CNNTransformerModel(nn.Module):
    def __init__(self, input_dim=6, hidden_dim=64, num_heads=4, num_transformer_layers=2, kernel_size=3, pred_len=1):
        super().__init__()
        self.pred_len = pred_len
        
        if hidden_dim % num_heads != 0:
            raise ValueError("hidden_dim必须能被num_heads整除")
        if kernel_size % 2 == 0:
            raise ValueError("卷积核大小应为奇数")
        
        self.cnn = nn.Sequential(
            nn.Conv1d(in_channels=input_dim, out_channels=hidden_dim, 
                      kernel_size=kernel_size, padding=kernel_size//2),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Conv1d(in_channels=hidden_dim, out_channels=hidden_dim, 
                      kernel_size=kernel_size, padding=kernel_size//2),
            nn.ReLU(),
            nn.Dropout(0.2)
        )
        
        self.transformer_encoder = nn.TransformerEncoder(
            nn.TransformerEncoderLayer(
                d_model=hidden_dim, nhead=num_heads, dim_feedforward=hidden_dim*4,
                batch_first=True, norm_first=True, dropout=0.1
            ),
            num_layers=num_transformer_layers
        )
        
        self.fc = nn.Linear(hidden_dim, pred_len)

    def forward(self, x):
        x_cnn = x.transpose(1, 2)
        x_cnn = self.cnn(x_cnn)
        x_cnn = x_cnn.transpose(1, 2)
        
        x_transformer = self.transformer_encoder(x_cnn)
        out = self.fc(x_transformer[:, -1, :])
        return out.unsqueeze(-1)

# 评估指标计算
def calculate_metrics(y_true, y_pred, epsilon=1e-8):
    y_true = np.array(y_true)
    y_pred = np.array(y_pred)
    if np.any(y_true == 0):
        y_true = y_true + epsilon
    
    mae = mean_absolute_error(y_true, y_pred)
    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100
    return round(mae, 6), round(mape, 4)

# 预测函数
def predict(model, loader):
    model.eval()
    preds, trues = [], []
    with torch.no_grad():
        for x, y in loader:
            x, y = x.to(DEVICE), y.to(DEVICE)
            pred = model(x)
            preds.extend(pred.cpu().numpy().flatten())
            trues.extend(y.cpu().numpy().flatten())
    return np.array(preds), np.array(trues)

# 逆变换函数
def inverse_transform(pred_scaled, target_scaler, original_target, seq_len, train_size, is_train=True):
    pred_diff = target_scaler.inverse_transform(pred_scaled.reshape(-1, 1)).flatten()
    start_idx = seq_len + 1
    if not is_train:
        start_idx += train_size
    prev_vals = original_target[start_idx-1 : start_idx-1 + len(pred_diff)]
    return prev_vals + pred_diff

# 数据预处理
def preprocess_data(df_daily):
    FEATURE_COLS = ['Global_reactive_power', 'Voltage', 'Global_intensity', 
                   'Sub_metering_1', 'Sub_metering_2', 'Sub_metering_3']
    TARGET_COL = 'Global_active_power'
    
    missing_cols = [col for col in FEATURE_COLS + [TARGET_COL] if col not in df_daily.columns]
    if missing_cols:
        raise ValueError(f"数据缺失列：{missing_cols}")
    
    feat_data = df_daily[FEATURE_COLS].values
    target_data = df_daily[TARGET_COL].values
    
    # 目标序列平稳化（一阶差分）
    diff_target = np.diff(target_data, n=1)
    feat_data_aligned = feat_data[1:]  # 对齐特征数据
    
    # 标准化
    feat_scaler = StandardScaler()
    target_scaler = StandardScaler()
    feat_data_scaled = feat_scaler.fit_transform(feat_data_aligned)
    diff_target_scaled = target_scaler.fit_transform(diff_target.reshape(-1, 1)).flatten()
    
    # 划分训练/测试集
    train_size = int(0.8 * len(feat_data_scaled))
    train_feat = feat_data_scaled[:train_size]
    train_target = diff_target_scaled[:train_size]
    test_feat = feat_data_scaled[train_size:]
    test_target = diff_target_scaled[train_size:]
    
    print(f"预处理完成：训练集{len(train_feat)}条 | 测试集{len(test_feat)}条")
    return {
        "train_feat": train_feat, "train_target": train_target,
        "test_feat": test_feat, "test_target": test_target,
        "feat_scaler": feat_scaler, "target_scaler": target_scaler,
        "FEATURE_COLS": FEATURE_COLS, "TARGET_COL": TARGET_COL,
        "original_target": target_data, "train_size": train_size
    }

# 模型训练与评估
def train_eval(prep_data, pred_len=1):
    print("\n" + "="*50)
    print("CNN-Transformer 训练与调参")
    print("="*50)
    
    # 超参数搜索空间
    param_grid = {
        'SEQ_LEN': [14, 28],
        'hidden_dim': [64, 128],
        'num_heads': [2, 4],
        'num_transformer_layers': [1, 2],
        'kernel_size': [3, 5],
        'BATCH_SIZE': [16, 32],
        'LEARNING_RATE': [1e-4, 5e-4]
    }
    
    # 生成有效参数组合
    n_trials = 8
    valid_params = []
    while len(valid_params) < n_trials:
        params = {k: random.choice(v) for k, v in param_grid.items()}
        if params['hidden_dim'] % params['num_heads'] == 0:
            valid_params.append(params)
    
    # 搜索最优参数
    best_mae = float('inf')
    best_params = None
    best_model = None
    
    for i, params in enumerate(tqdm(valid_params, desc="调参进度")):
        try:
            # 构建数据集
            train_dataset = MultiFeatureTimeSeriesDataset(
                prep_data["train_feat"], prep_data["train_target"],
                seq_len=params['SEQ_LEN'], pred_len=pred_len
            )
            test_dataset = MultiFeatureTimeSeriesDataset(
                prep_data["test_feat"], prep_data["test_target"],
                seq_len=params['SEQ_LEN'], pred_len=pred_len
            )
            
            if len(train_dataset) < 20 or len(test_dataset) < 10:
                continue
            
            # 数据加载器
            train_loader = DataLoader(train_dataset, batch_size=params['BATCH_SIZE'], shuffle=False)
            test_loader = DataLoader(test_dataset, batch_size=params['BATCH_SIZE'], shuffle=False)
            
            # 初始化模型
            model = CNNTransformerModel(
                input_dim=len(prep_data["FEATURE_COLS"]),
                hidden_dim=params['hidden_dim'],
                num_heads=params['num_heads'],
                num_transformer_layers=params['num_transformer_layers'],
                kernel_size=params['kernel_size'],
                pred_len=pred_len
            ).to(DEVICE)
            
            # 训练配置
            criterion = nn.L1Loss()
            optimizer = optim.Adam(model.parameters(), lr=params['LEARNING_RATE'], weight_decay=1e-5)
            epochs = 50
            
            # 模型训练
            model.train()
            for _ in range(epochs):
                for x_batch, y_batch in train_loader:
                    x_batch, y_batch = x_batch.to(DEVICE), y_batch.to(DEVICE)
                    y_pred = model(x_batch)
                    loss = criterion(y_pred, y_batch)
                    
                    optimizer.zero_grad()
                    loss.backward()
                    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
                    optimizer.step()
            
            # 测试集预测与评估
            test_pred_scaled, test_true_scaled = predict(model, test_loader)
            test_pred = inverse_transform(
                test_pred_scaled, prep_data["target_scaler"], prep_data["original_target"],
                params['SEQ_LEN'], prep_data["train_size"], is_train=False
            )
            test_true = inverse_transform(
                test_true_scaled, prep_data["target_scaler"], prep_data["original_target"],
                params['SEQ_LEN'], prep_data["train_size"], is_train=False
            )
            
            mae, mape = calculate_metrics(test_true, test_pred)
            
            # 更新最优模型
            if mae < best_mae:
                best_mae = mae
                best_mape = mape
                best_params = params
                best_model = model
        
        except Exception as e:
            print(f"第{i+1}组参数训练失败：{str(e)}")
            continue
    
    # 保存最优模型
    torch.save({
        'model_state_dict': best_model.state_dict(),
        'params': best_params,
        'feat_scaler': prep_data["feat_scaler"],
        'target_scaler': prep_data["target_scaler"]
    }, "best_model/cnn_transformer_best.pth")
    
    # 最优模型可视化
    train_dataset = MultiFeatureTimeSeriesDataset(
        prep_data["train_feat"], prep_data["train_target"],
        seq_len=best_params['SEQ_LEN'], pred_len=pred_len
    )
    train_loader = DataLoader(train_dataset, batch_size=best_params['BATCH_SIZE'], shuffle=False)
    
    # 训练集预测
    train_pred_scaled, train_true_scaled = predict(best_model, train_loader)
    train_pred = inverse_transform(
        train_pred_scaled, prep_data["target_scaler"], prep_data["original_target"],
        best_params['SEQ_LEN'], prep_data["train_size"], is_train=True
    )
    train_true = inverse_transform(
        train_true_scaled, prep_data["target_scaler"], prep_data["original_target"],
        best_params['SEQ_LEN'], prep_data["train_size"], is_train=True
    )
    
    # 计算训练集指标
    train_mae, train_mape = calculate_metrics(train_true, train_pred)
    
    # 绘制可视化图
    fig, ax = plt.subplots(figsize=(15, 6))
    train_steps = range(len(train_true))
    test_steps = range(len(train_true), len(train_true) + len(test_true))
    
    ax.plot(train_steps, train_true, color='#2E86AB', linewidth=2.0, 
            label=f'训练集真实值 (MAE={train_mae:.2f})', alpha=0.8)
    ax.plot(train_steps, train_pred, color='#F2A154', linewidth=1.8, 
            label='训练集预测值', alpha=0.9)
    ax.plot(test_steps, test_true, color='#2E86AB', linewidth=2.5, 
            label=f'测试集真实值 (MAE={best_mae:.2f})', alpha=0.8)
    ax.plot(test_steps, test_pred, color='#E63946', linewidth=2.2, 
            label='测试集预测值', linestyle='--', alpha=0.9)
    
    ax.axvline(x=len(train_true), color='black', linestyle=':', linewidth=2.0, label='训练/测试分割线')
    ax.set_title('电力消耗预测结果', fontsize=14, fontweight='bold')
    ax.set_xlabel('时间步'), ax.set_ylabel('电力消耗 (kW)'), ax.grid(alpha=0.3)
    ax.legend(), plt.tight_layout(), plt.savefig("best_model/prediction_result.png", dpi=300), plt.close()
    
    # 输出最优结果
    print(f"\n最优结果：")
    print(f"最优参数：{best_params}")
    print(f"训练集MAE：{train_mae:.6f} | MAPE：{train_mape:.4f}%")
    print(f"测试集MAE：{best_mae:.6f} | MAPE：{best_mape:.4f}%")
    print("模型与可视化已保存至 best_model/ 目录")
    
    return {
        "model_name": "CNN-Transformer",
        "params": best_params,
        "train_mae": train_mae,
        "test_mae": best_mae,
        "test_mape": best_mape
    }

# 主函数
def main(data_path=None):
    print("="*60)
    print("电力消耗预测项目")
    print("="*60)
    
    try:
        # 数据加载
        df = load_data(data_path)
        # 探索性数据分析
        df_daily = exploratory_data_analysis(df)
        # 数据预处理
        prep_data = preprocess_data(df_daily)
        # 模型训练与评估
        result = train_eval(prep_data)
        
        print("\n" + "="*60)
        print("项目运行完成！")
        print("="*60)
        print("输出文件清单：")
        print("- EDA可视化：eda_plots/ 目录")
        print("- 最优模型权重：best_model/cnn_transformer_best.pth")
        print("- 预测结果图：best_model/prediction_result.png")
    
    except Exception as e:
        print(f"\n运行失败：{str(e)}")
        raise

if __name__ == "__main__":
    DATA_PATH = "consumption.csv"
    main(data_path=DATA_PATH)
