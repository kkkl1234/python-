import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_absolute_error
import random
from tqdm import tqdm
import os
import warnings
warnings.filterwarnings('ignore')

# 基础配置
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
os.makedirs("best_model", exist_ok=True)
os.makedirs("eda_plots", exist_ok=True)

# 评估指标计算
def calculate_mae(y_true, y_pred):
    return mean_absolute_error(y_true, y_pred)

def calculate_mape(y_true, y_pred, epsilon=1e-8):
    y_true = np.array(y_true) + epsilon
    y_pred = np.array(y_pred)
    return round(np.mean(np.abs((y_true - y_pred) / y_true)) * 100, 4)

# -------------------------- 核心类定义 --------------------------
class TimeSeriesDataset(Dataset):
    def __init__(self, data, seq_len, pred_len=1):
        self.data = data
        self.seq_len = seq_len
        self.pred_len = pred_len
        
        if len(data) < seq_len + pred_len:
            raise ValueError(f"数据长度({len(data)})不足，需至少{seq_len + pred_len}个样本")
        self.length = len(data) - seq_len - pred_len + 1

    def __len__(self):
        return self.length

    def __getitem__(self, idx):
        if idx < 0 or idx >= self.length:
            raise IndexError(f"索引{idx}超出范围（0-{self.length-1}）")
        x = self.data[idx:idx+self.seq_len]
        y = self.data[idx+self.seq_len:idx+self.seq_len+self.pred_len]
        return torch.tensor(x, dtype=torch.float32).unsqueeze(-1), torch.tensor(y, dtype=torch.float32).unsqueeze(-1)

class CNNTransformerModel(nn.Module):
    def __init__(self, input_dim=1, hidden_dim=64, num_heads=4, num_transformer_layers=2, kernel_size=3, pred_len=1):
        super().__init__()
        if hidden_dim % num_heads != 0:
            raise ValueError(f"hidden_dim({hidden_dim})必须能被num_heads({num_heads})整除")
        
        self.cnn = nn.Sequential(
            nn.Conv1d(input_dim, hidden_dim, kernel_size, padding=kernel_size-1, dilation=1),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Conv1d(hidden_dim, hidden_dim, kernel_size, padding=2*(kernel_size-1), dilation=2),
            nn.ReLU(),
            nn.Dropout(0.2)
        )
        self.transformer_encoder = nn.TransformerEncoder(
            nn.TransformerEncoderLayer(
                d_model=hidden_dim, nhead=num_heads, dim_feedforward=hidden_dim*4,
                batch_first=True, norm_first=True, dropout=0.1
            ),
            num_layers=num_transformer_layers
        )
        self.fc = nn.Linear(hidden_dim, pred_len)

    def forward(self, x):
        x_cnn = x.transpose(1, 2)
        x_cnn = self.cnn(x_cnn).transpose(1, 2)
        x_transformer = self.transformer_encoder(x_cnn)
        return self.fc(x_transformer[:, -1, :]).unsqueeze(-1)

# -------------------------- 数据加载 --------------------------
def load_public_data():
    data_path = "consumption.csv"
    df = pd.read_csv(data_path)
    
    df["DateTime"] = pd.to_datetime(df["DateTime"])  
    df.set_index("DateTime", inplace=True)  
    
    df_daily_mean = df.resample('D').mean() 
    # 新增：提取预测目标列，保留单变量时间序列
    target_col = "Zone 3  Power Consumption"
    df_daily_mean = df_daily_mean[[target_col]]  # 只保留目标列，形状变为(364,1)
    return df_daily_mean

# -------------------------- 探索性数据分析 --------------------------
def exploratory_data_analysis(df):
    print("\n" + "="*50)
    print("探索性数据分析")
    print("="*50)
    print(f"数据形状：{df.shape} | 时间范围：{df.index.min()} 至 {df.index.max()}")
    print("\n描述统计：")
    print(df.describe().round(2))
    
    # 时间序列图：修复多列数据问题，只取第一列（电力消耗列）进行绘图
    plt.figure(figsize=(15, 5))
    # 修改点1：使用df.iloc[:, 0]获取单列数据，避免多数据集
    plt.plot(df.index, df.iloc[:, 0].values, color='#2E86AB', linewidth=1.5)
    plt.title('日均电力消耗时间序列', fontsize=14, fontweight='bold')
    plt.xlabel('日期'), plt.ylabel('电力消耗 (kW)'), plt.grid(alpha=0.3)
    plt.tight_layout(), plt.savefig("eda_plots/time_series.png", dpi=300), plt.close()
    
    # 分布直方图：修复多列数据问题，只取第一列展平为一维数组
    plt.figure(figsize=(10, 6))
    # 修改点2：使用df.iloc[:, 0].values.flatten()获取单组数据
    plt.hist(df.iloc[:, 0].values.flatten(), bins=30, color='#F2A154', alpha=0.7, edgecolor='black')
    plt.title('电力消耗分布', fontsize=14, fontweight='bold')
    plt.xlabel('电力消耗 (kW)'), plt.ylabel('频数'), plt.grid(alpha=0.3)
    plt.tight_layout(), plt.savefig("eda_plots/distribution.png", dpi=300), plt.close()
    print("EDA可视化已保存至 eda_plots/ 目录")
    return df

# -------------------------- 数据预处理 --------------------------
def preprocess_data(df):
    # 一阶差分平稳化（此时df是(364,1)，差分后为(363,1)）
    diff_series = df.diff(1).dropna()  # 形状(363,1)
    # 标准化处理：直接对(363,1)的差分序列处理，无需reshape(-1,1)
    scaler = StandardScaler()
    diff_series_scaled = scaler.fit_transform(diff_series).flatten()  # 形状(363,)
    
    # 训练/测试集划分（基于真实的363条时序数据）
    train_size = int(0.8 * len(diff_series_scaled))  # 0.8×363≈290
    train_data = diff_series_scaled[:train_size]     # 约290条
    test_data = diff_series_scaled[train_size:]      # 约73条
    
    print(f"数据预处理完成：训练集{len(train_data)}条 | 测试集{len(test_data)}条")
    return train_data, test_data, scaler, diff_series.index

# -------------------------- 训练与评估 --------------------------
def train_eval(params, train_data, test_data, scaler, df_original, pred_len, epochs):
    try:
        train_dataset = TimeSeriesDataset(train_data, params['SEQ_LEN'], pred_len)
        test_dataset = TimeSeriesDataset(test_data, params['SEQ_LEN'], pred_len)
    except Exception as e:
        print(f"数据集构建失败：{e}")
        return float('inf'), float('inf'), None
    
    if len(train_dataset) < 10 or len(test_dataset) < 5:
        return float('inf'), float('inf'), None
    
    train_loader = DataLoader(train_dataset, batch_size=params['BATCH_SIZE'], shuffle=False)
    test_loader = DataLoader(test_dataset, batch_size=params['BATCH_SIZE'], shuffle=False)
    
    model = CNNTransformerModel(
        hidden_dim=params['hidden_dim'], num_heads=params['num_heads'],
        num_transformer_layers=params['num_transformer_layers'], kernel_size=params['kernel_size'],
        pred_len=pred_len
    ).to(DEVICE)
    
    criterion = nn.L1Loss()
    optimizer = optim.Adam(model.parameters(), lr=params['LEARNING_RATE'], weight_decay=1e-5)
    
    # 模型训练
    for _ in range(epochs):
        model.train()
        for x_batch, y_batch in train_loader:
            x_batch, y_batch = x_batch.to(DEVICE), y_batch.to(DEVICE)
            y_pred = model(x_batch)
            loss = criterion(y_pred, y_batch)
            
            optimizer.zero_grad()
            loss.backward()
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
            optimizer.step()
    
    # 预测函数
    def predict(model, loader):
        model.eval()
        preds, trues = [], []
        with torch.no_grad():
            for x, y in loader:
                x, y = x.to(DEVICE), y.to(DEVICE)
                pred = model(x)
                preds.extend(pred.cpu().numpy().flatten())
                trues.extend(y.cpu().numpy().flatten())
        return np.array(preds), np.array(trues)
    
    # 逆变换函数
    def inverse_transform(pred_scaled, is_train=True):
        pred_diff = scaler.inverse_transform(pred_scaled.reshape(-1, 1)).flatten()
        start_idx = params['SEQ_LEN'] if is_train else len(train_data) + params['SEQ_LEN']
        original_vals = df_original.iloc[start_idx-1 : start_idx-1 + len(pred_diff)].values
        return original_vals + pred_diff
    
    # 测试集评估
    test_pred_scaled, test_true_scaled = predict(model, test_loader)
    test_pred = inverse_transform(test_pred_scaled, is_train=False)
    test_true = inverse_transform(test_true_scaled, is_train=False)
    
    test_mae = calculate_mae(test_true, test_pred)
    test_mape = calculate_mape(test_true, test_pred)
    return test_mae, test_mape, model

# -------------------------- 最优模型可视化 --------------------------
def visualize_best_model(best_params, best_model, train_data, test_data, scaler, df_original, pred_len):
    # 构建数据集
    best_train_dataset = TimeSeriesDataset(train_data, best_params['SEQ_LEN'], pred_len)
    best_test_dataset = TimeSeriesDataset(test_data, best_params['SEQ_LEN'], pred_len)
    best_train_loader = DataLoader(best_train_dataset, batch_size=best_params['BATCH_SIZE'], shuffle=False)
    best_test_loader = DataLoader(best_test_dataset, batch_size=best_params['BATCH_SIZE'], shuffle=False)
    
    # 预测函数
    def predict(model, loader):
        model.eval()
        preds, trues = [], []
        with torch.no_grad():
            for x, y in loader:
                x, y = x.to(DEVICE), y.to(DEVICE)
                pred = model(x)
                preds.extend(pred.cpu().numpy().flatten())
                trues.extend(y.cpu().numpy().flatten())
        return np.array(preds), np.array(trues)
    
    # 生成预测结果
    train_pred_scaled, train_true_scaled = predict(best_model, best_train_loader)
    test_pred_scaled, test_true_scaled = predict(best_model, best_test_loader)
    
    # 逆变换
    def inverse_transform_final(pred_scaled, is_train=True):
        pred_diff = scaler.inverse_transform(pred_scaled.reshape(-1, 1)).flatten()
        start_idx = best_params['SEQ_LEN'] if is_train else len(train_data) + best_params['SEQ_LEN']
        original_vals = df_original.iloc[start_idx-1 : start_idx-1 + len(pred_diff)].values
        return original_vals + pred_diff
    
    train_pred = inverse_transform_final(train_pred_scaled, is_train=True)
    train_true = inverse_transform_final(train_true_scaled, is_train=True)
    test_pred = inverse_transform_final(test_pred_scaled, is_train=False)
    test_true = inverse_transform_final(test_true_scaled, is_train=False)
    
    # 绘制图表
    fig, ax = plt.subplots(figsize=(15, 6))
    train_steps = range(len(train_true))
    test_steps = range(len(train_true), len(train_true) + len(test_true))
    
    ax.plot(train_steps, train_true, color='#2E86AB', linewidth=2.0, 
            label=f'训练集真实值 (MAE={calculate_mae(train_true, train_pred):.2f})', alpha=0.8)
    ax.plot(train_steps, train_pred, color='#F2A154', linewidth=1.8, label='训练集预测值', alpha=0.9)
    ax.plot(test_steps, test_true, color='#2E86AB', linewidth=2.5, 
            label=f'测试集真实值 (MAE={calculate_mae(test_true, test_pred):.2f})', alpha=0.8)
    ax.plot(test_steps, test_pred, color='#E63946', linewidth=2.2, label='测试集预测值', linestyle='--', alpha=0.9)
    ax.axvline(x=len(train_true)-1, color='black', linestyle=':', linewidth=2.0, label='训练/测试分割线')
    
    ax.set_title('电力消耗预测结果（CNN-Transformer）', fontsize=14, fontweight='bold')
    ax.set_xlabel('时间步'), ax.set_ylabel('电力消耗 (kW)'), ax.grid(alpha=0.3), ax.legend()
    plt.tight_layout(), plt.savefig("best_model/prediction_result.png", dpi=300), plt.close()
    print("预测结果可视化已保存")

# -------------------------- 主函数 --------------------------
def main():
    print("="*60)
    print("电力消耗预测项目")
    print("="*60)
    
    # 全局参数
    PRED_LEN = 1
    EPOCHS_BASE = 40
    
    # 超参数搜索空间
    param_grid = {
        'SEQ_LEN': [14, 28],
        'hidden_dim': [32, 64, 128],
        'num_heads': [2, 4, 8],
        'num_transformer_layers': [1, 2, 3],
        'kernel_size': [3, 5],
        'BATCH_SIZE': [16, 32],
        'LEARNING_RATE': [1e-4, 5e-4]
    }
    
    # 生成20组有效参数
    n_trials = 20
    random_params = []
    while len(random_params) < n_trials:
        params = {k: random.choice(v) for k, v in param_grid.items()}
        if params['hidden_dim'] % params['num_heads'] == 0:
            random_params.append(params)
    
    try:
        # 数据加载与EDA
        df_original = load_public_data()
        df_original = exploratory_data_analysis(df_original)
        
        # 数据预处理
        train_data, test_data, scaler, diff_index = preprocess_data(df_original)
        
        # 超参数搜索
        print("\n===== 开始20组超参数搜索 =====")
        results = []
        for i, params in enumerate(tqdm(random_params, desc="调参进度")):
            test_mae, test_mape, model = train_eval(params, train_data, test_data, scaler, df_original, PRED_LEN, EPOCHS_BASE)
            results.append({'params': params, 'test_mae': test_mae, 'test_mape': test_mape, 'model': model})
            print(f"第{i+1}组：MAE={test_mae:.6f} | MAPE={test_mape:.4f}%")
        
        # 筛选最优模型
        valid_results = [r for r in results if r['test_mae'] != float('inf')]
        if not valid_results:
            raise ValueError("无有效模型，请检查数据或参数范围")
        best_result = sorted(valid_results, key=lambda x: x['test_mae'])[0]
        best_params = best_result['params']
        best_model = best_result['model']
        best_mae = best_result['test_mae']
        best_mape = best_result['test_mape']
        
        # 最优模型可视化
        visualize_best_model(best_params, best_model, train_data, test_data, scaler, df_original, PRED_LEN)
        
        # 保存最优模型
        torch.save({
            'model_state_dict': best_model.state_dict(),
            'params': best_params,
            'scaler': scaler,
            'test_mae': best_mae,
            'test_mape': best_mape
        }, "best_model/best_model.pth")
        
        # 结果输出
        print("\n" + "="*60)
        print("最优模型结果汇总")
        print("="*60)
        print(f"最优参数：{best_params}")
        print(f"测试集MAE：{best_mae:.6f} kW | MAPE：{best_mape:.4f}%")
        print(f"\n输出文件：")
        print("- EDA可视化：eda_plots/")
        print("- 最优模型权重：best_model/best_model.pth")
        print("- 预测结果图：best_model/prediction_result.png")
    
    except Exception as e:
        print(f"\n运行失败：{str(e)}")
        raise

if __name__ == "__main__":
    main()
